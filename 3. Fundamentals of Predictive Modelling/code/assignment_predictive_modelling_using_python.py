# -*- coding: utf-8 -*-
"""Assignment_Predictive Modelling using Python.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tRUn4O4prhLx-UZYLzub2TyJLV1WEnZr

# Assignment Predictive Modelling Using Python

BACKGROUND

The data for modeling contains information on Selling price of each house in million Rs. It also contains Carpet area in square feet, Distance from nearest metro station and Number of schools within 2 km distance. The data has 198 rows and 5 columns.

Notes:

Dependent Variable:
- Houses selling price

Indepented variables:
- Carpet area in square feet
- Distance from nearest metro station
- Number of schools within 2 km distance

# Question 1 : Import House Price Data. Check the structure of the data

### Import House Price Data. Check the structure of the data

This step involves loading the dataset from a CSV file and displaying the first few rows to understand the structure of the data.
"""

import pandas as pd

# Import data
data = pd.read_csv("/content/House Price Data.csv")

# Display first few rows of data
data.head()

# Remove the column named "Houseid" from the dataset data
data.drop(columns=['Houseid'], inplace=True)
data.head()

# Check the structure of the data
data.info()

data.describe()

#!pip install ydata-profiling
from ydata_profiling import ProfileReport

profile = ProfileReport(data)
profile

"""### Correlation Matrix using Heatmap

A heatmap of the correlation matrix helps visualize the relationships between variables, with color gradients representing the strength of the correlations.
"""

import seaborn as sns
correlation_matrix = data.corr().round(2)
sns.heatmap(data=correlation_matrix, annot=True)

"""Observations:
- Price and Area: There is a strong positive correlation. As the area of the house increass, the price of the house tends to increase as well.
- Price and Distance: Moderate negative correlation. As the distance from the metro station increases, the price of the house tends to decrease.
- Price and Schools: There is a positive correlation. Houses close more schools tend to have higher prices.

# Question 2 : Split the data into Training (80%) and Testing (20%) data sets

### Split the data into Training (80%) and Testing (20%) data sets

Splitting the data into training and testing sets allows us to build and evaluate the model on different subsets of the data, which helps in assessing the model's performance.
"""

# Load necessary libraries
from sklearn.model_selection import train_test_split

# Split data
# 80% of the data is selected for the training set
X = data.drop(columns=['Price'])
Y = data['Price']

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state=123)

"""# Question 3 : Build a regression model on training data to estimate selling price of a House.

### Build a regression model on training data to estimate selling price of a House.

This step involves fitting a linear regression model to the training data to establish the relationship between the dependent variable and the independent variables
"""

# Build model
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error

model = LinearRegression()
model.fit(X_train, Y_train)

model.coef_

"""#Question 4 : List down significant variables and interpret their regression coefficients

### List down significant variables and interpret their regression coefficients

The summary of the linear regression model includes parameter estimates (coefficients), R-squared value, p-values, and other statistics that help evaluate the model
"""

import statsmodels.api as sm

# Define your formula
formula = 'Price ~ ' + ' + '.join(data.columns.drop('Price'))

# Fit the linear regression model
data_model = sm.OLS.from_formula(formula, data=data).fit()

# Why not using this instead???
#data_model = sm.OLS(Y_train,X_train).fit()

# Print the model summary
print(data_model.summary())

"""Observations:
- All variables are significant as p values are smaller than 0.05
-  The coefficients for the predictor variables suggest their respective impact on the price. The variables Area and Schools have positive effects, while Distance has a negative effect.

# Question 5 : What is the R2 and adjusted R2 of the model? Give interpretation

### What is the R2 and adjusted R2 of the model? Give interpretation


- The model’s R² value is 0.794, indicating that approximately 79% of the variability in Price is explained by the model.

R² values can sometimes be misleading as adding more predictors to a model can artificially inflate the R² value, even if the predictors are irrelevant.

- The Adjusted R-squared is 0.791. Adjusted R-squared adjusts the R² statistic based on the number of predictors in the model.
As we can see they are comparable.

Unlike R², the Adjusted R² can decrease if predictors do not improve the model beyond what would be expected by chance.

It is always lower or equal to R², and it provides a more honest representation of the model fit when dealing with multiple predictors.

As we can see they are comparable.

# Question 6 : Is there a multicollinearity problem? If yes, do the necessary steps to remove it

The Variance Inflation Factor (VIF) measures the extent of multicollinearity in the regression model. High VIF values indicate multicollinearity issues.
"""

import patsy
import pandas as pd
from statsmodels.stats.outliers_influence import variance_inflation_factor

# Create the design matrix
y, X = patsy.dmatrices(formula, data, return_type='dataframe')

# Calculate VIF for each predictor variable
vif_data = pd.DataFrame()
vif_data["Variable"] = X.columns
vif_data["VIF"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]

# Print the VIF DataFrame
print(vif_data)

"""Observations:
- There is no multicollinearity problem as all VIF’s are less than 5

# Question 7 : Are there any influential observations in the data?

Influential observations in a dataset is an important step in regression analysis, as these points can disproportionately affect the results of the model.
"""

from statsmodels.stats.outliers_influence import OLSInfluence

# Calculate influence measures
influence = OLSInfluence(data_model)

# Display summary of influence measures
print(influence.summary_frame())

from statsmodels.graphics.regressionplots import influence_plot
import matplotlib.pyplot as plt
influence_plot(data_model)

n=data.shape[0]
k=data.shape[1]
leverage_cutoff =3*(k+1)/n
plt.axvline(x=leverage_cutoff,linestyle=':',label='Leverage Cutoff')
plt.legend()
plt.show()

"""Observations:
- There are influential as indicated by the large circle sizes. They have a substantial effect on the regression model.

# Question 8 : Can we assume that errors follow ‘Normal’ distribution?

The histogram and Q-Q plot help check if the residuals follow a normal distribution, which is an assumption of linear regression.

If the residuals follow a normal distribution, it validates one of the regression assumptions, supporting the reliability of confidence intervals and hypothesis tests.

If the data are truly sampled from a normal distribution the Q-Q plot will be linear
"""

# Add fitted values and residuals to the DataFrame
data['fit'] = data_model.fittedvalues
data['resi'] = data_model.resid


import scipy.stats as stats
import matplotlib.pyplot as plt

# Assuming 'data' is a pandas DataFrame
# Assuming 'data_model1' is the fitted linear regression model

# Q-Q plot of residuals
stats.probplot(data['resi'], dist="norm", plot=plt)
plt.title('Q-Q Plot of Residuals')
plt.xlabel('Theoretical Quantiles')
plt.ylabel('Sample Quantiles')
plt.show()

"""Observation: The points do not seems to sit on a line"""

# Shapiro-Wilk test for normality
shapiro_test = stats.shapiro(data['resi'])
print("Shapiro-Wilk test p-value:", shapiro_test.pvalue)

"""The Shapiro-Wilk test, commonly referred to as the Shapiro test, is a statistical test used to assess the normality of a dataset.

the p-value is less than 0.05, the null hypothesis is rejected, indicating that the data do not follow a normal distribution.

# Question 9 : Is there a Heteroscedasticity problem? Check using residual vs. predictor plots.

We want to diagnose the fit of the model by visualizing the distribution of residuals (errors).

Ideally, residuals should be randomly scattered around zero.

If the residuals are randomly scattered around zero, it suggests that the model’s assumptions are likely satisfied and the model provides a good fit.
"""

# Create a residual plot
plt.figure(figsize=(8, 6))
plt.scatter(data['fit'], data['resi'], alpha=0.5)
plt.axhline(y=0, color='r', linestyle='--')
plt.xlabel('Fitted values')
plt.ylabel('Residuals')
plt.title('Residual Plot')
plt.show()

"""Observation:
- Residuals in the model are randomly distributed indicating NO presence of Heteroscedasticity

# Question 10: Calculate the RMSE for the Training and Testing data. Multiple Linear Regression

The Root Mean Squared Error (RMSE) measures the average magnitude of the errors between predicted and actual values, providing an indication of model accuracy.
"""

from sklearn.metrics import mean_squared_error
from sklearn.metrics import r2_score
import numpy as np

y_train_predict = model.predict(X_train)
rmse = (np.sqrt(mean_squared_error(Y_train, y_train_predict)))
r2 = r2_score(Y_train, y_train_predict)

print('RMSE is {}'.format(rmse))

print('R2 score is {}'.format(r2))

"""Validating the model on the test set using RMSE helps assess its performance on unseen data."""

y_test_predict = model.predict(X_test)
rmse = (np.sqrt(mean_squared_error(Y_test, y_test_predict)))
r2 = r2_score(Y_test, y_test_predict)

print('RMSE is {}'.format(rmse))

print('R2 score is {}'.format(r2))

"""Obseravation:The similarity in RMSE between the test and train data suggests that the regression model generalizes reasonably well, with consistent prediction accuracy on both datasets. This implies that the model is stable and not overfitting to the training data."""

from sklearn.model_selection import cross_val_score
from sklearn.model_selection import KFold

folds = KFold(n_splits = 4, shuffle = True, random_state = 100)
scores = cross_val_score(model, X, Y, scoring='r2', cv=folds)


print("Mean 4-Fold R Squared: {}".format(np.mean(scores)))

cv_rmse_scores= cross_val_score(model, X, Y, cv=folds, scoring='neg_mean_squared_error')
np.sqrt(-(np.mean(cv_rmse_scores)))

"""Comment: RMSE and R squared values using K-fold validation are similar to overall RMSE and R squared
values
"""